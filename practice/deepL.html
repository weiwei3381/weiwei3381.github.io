<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度学习与实践 | 小熊的技术文档</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/fav.ico">
    <link rel="stylesheet" href="/css/katex.min.css">
    <link rel="stylesheet" href="/css/github-markdown.min.css">
    <meta name="description" content="衣带渐宽终不悔，为伊消得人憔悴">
    
    <link rel="preload" href="/assets/css/0.styles.f841f567.css" as="style"><link rel="preload" href="/assets/js/app.172e5c27.js" as="script"><link rel="preload" href="/assets/js/2.983eb755.js" as="script"><link rel="preload" href="/assets/js/50.f25489e0.js" as="script"><link rel="prefetch" href="/assets/js/10.609f238e.js"><link rel="prefetch" href="/assets/js/11.c724f89a.js"><link rel="prefetch" href="/assets/js/12.d06db9a0.js"><link rel="prefetch" href="/assets/js/13.54ef98aa.js"><link rel="prefetch" href="/assets/js/14.395e2b25.js"><link rel="prefetch" href="/assets/js/15.267ab24d.js"><link rel="prefetch" href="/assets/js/16.3a1d6a3d.js"><link rel="prefetch" href="/assets/js/17.511ee7ec.js"><link rel="prefetch" href="/assets/js/18.3af7782b.js"><link rel="prefetch" href="/assets/js/19.7ddd4ea1.js"><link rel="prefetch" href="/assets/js/20.8a7143cc.js"><link rel="prefetch" href="/assets/js/21.6b97d8cd.js"><link rel="prefetch" href="/assets/js/22.c585fce6.js"><link rel="prefetch" href="/assets/js/23.b0fcb690.js"><link rel="prefetch" href="/assets/js/24.ca223bca.js"><link rel="prefetch" href="/assets/js/25.014e71b5.js"><link rel="prefetch" href="/assets/js/26.528837b7.js"><link rel="prefetch" href="/assets/js/27.03e05e51.js"><link rel="prefetch" href="/assets/js/28.80229a71.js"><link rel="prefetch" href="/assets/js/29.51838c3e.js"><link rel="prefetch" href="/assets/js/3.4e77dfef.js"><link rel="prefetch" href="/assets/js/30.c5136fb3.js"><link rel="prefetch" href="/assets/js/31.355c2d8b.js"><link rel="prefetch" href="/assets/js/32.10c26156.js"><link rel="prefetch" href="/assets/js/33.7e7fac82.js"><link rel="prefetch" href="/assets/js/34.89a85b94.js"><link rel="prefetch" href="/assets/js/35.fb738fef.js"><link rel="prefetch" href="/assets/js/36.a8fe1d78.js"><link rel="prefetch" href="/assets/js/37.d136dff5.js"><link rel="prefetch" href="/assets/js/38.73e50b4c.js"><link rel="prefetch" href="/assets/js/39.1cbe227d.js"><link rel="prefetch" href="/assets/js/4.772ac0bd.js"><link rel="prefetch" href="/assets/js/40.a83eec21.js"><link rel="prefetch" href="/assets/js/41.573ff2da.js"><link rel="prefetch" href="/assets/js/42.61544b41.js"><link rel="prefetch" href="/assets/js/43.ec09f4c1.js"><link rel="prefetch" href="/assets/js/44.cd1cea5b.js"><link rel="prefetch" href="/assets/js/45.83f86d1b.js"><link rel="prefetch" href="/assets/js/46.66ead5ac.js"><link rel="prefetch" href="/assets/js/47.13ba3a60.js"><link rel="prefetch" href="/assets/js/48.cc87de5f.js"><link rel="prefetch" href="/assets/js/49.0d985233.js"><link rel="prefetch" href="/assets/js/5.3c7852ef.js"><link rel="prefetch" href="/assets/js/51.9d6635ee.js"><link rel="prefetch" href="/assets/js/52.e29dfe30.js"><link rel="prefetch" href="/assets/js/53.de0678ce.js"><link rel="prefetch" href="/assets/js/54.6580c438.js"><link rel="prefetch" href="/assets/js/6.54e1cc95.js"><link rel="prefetch" href="/assets/js/7.53bcef6c.js"><link rel="prefetch" href="/assets/js/8.37dd4b7c.js"><link rel="prefetch" href="/assets/js/9.26cfd48c.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f841f567.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">小熊的技术文档</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/front-end/" class="nav-link">
  🎨前端
</a></div><div class="nav-item"><a href="/back-end/" class="nav-link">
  💻后端
</a></div><div class="nav-item"><a href="/office/" class="nav-link">
  🏢办公
</a></div><div class="nav-item"><a href="/practice/" class="nav-link router-link-active">
  🚀实战
</a></div><div class="nav-item"><a href="/general/" class="nav-link">
  🍓通用
</a></div><div class="nav-item"><a href="/general/fast.html" class="nav-link">
  ⚡快速笔记
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🦉近期重点" class="dropdown-title"><span class="title">🦉近期重点</span> <span class="arrow down"></span></button> <button type="button" aria-label="🦉近期重点" class="mobile-dropdown-title"><span class="title">🦉近期重点</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/practice/book.html" class="nav-link">
  📚常用技术书籍
</a></li><li class="dropdown-item"><!----> <a href="/office/other.html" class="nav-link">
  💼常用办公技巧
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⭐️资源" class="dropdown-title"><span class="title">⭐️资源</span> <span class="arrow down"></span></button> <button type="button" aria-label="⭐️资源" class="mobile-dropdown-title"><span class="title">⭐️资源</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://www.birdiesearch.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  小鸟搜索
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://salttiger.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  每天一本编程书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://metaso.cn/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  秘塔AI搜索
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/front-end/" class="nav-link">
  🎨前端
</a></div><div class="nav-item"><a href="/back-end/" class="nav-link">
  💻后端
</a></div><div class="nav-item"><a href="/office/" class="nav-link">
  🏢办公
</a></div><div class="nav-item"><a href="/practice/" class="nav-link router-link-active">
  🚀实战
</a></div><div class="nav-item"><a href="/general/" class="nav-link">
  🍓通用
</a></div><div class="nav-item"><a href="/general/fast.html" class="nav-link">
  ⚡快速笔记
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🦉近期重点" class="dropdown-title"><span class="title">🦉近期重点</span> <span class="arrow down"></span></button> <button type="button" aria-label="🦉近期重点" class="mobile-dropdown-title"><span class="title">🦉近期重点</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/practice/book.html" class="nav-link">
  📚常用技术书籍
</a></li><li class="dropdown-item"><!----> <a href="/office/other.html" class="nav-link">
  💼常用办公技巧
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="⭐️资源" class="dropdown-title"><span class="title">⭐️资源</span> <span class="arrow down"></span></button> <button type="button" aria-label="⭐️资源" class="mobile-dropdown-title"><span class="title">⭐️资源</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://www.birdiesearch.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  小鸟搜索
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://salttiger.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  每天一本编程书
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://metaso.cn/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  秘塔AI搜索
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/practice/book.html" class="sidebar-link">外文技术书籍推荐</a></li><li><a href="/practice/deepL.html" aria-current="page" class="active sidebar-link">深度学习与实践</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/practice/deepL.html#numpy常用api" class="sidebar-link">numpy常用API</a></li><li class="sidebar-sub-header"><a href="/practice/deepL.html#torch常用api" class="sidebar-link">torch常用API</a></li><li class="sidebar-sub-header"><a href="/practice/deepL.html#hugging-face实战" class="sidebar-link">Hugging Face实战</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/practice/deepL.html#transformer各种任务介绍" class="sidebar-link">transformer各种任务介绍</a></li><li class="sidebar-sub-header"><a href="/practice/deepL.html#常用api" class="sidebar-link">常用API</a></li><li class="sidebar-sub-header"><a href="/practice/deepL.html#pipeline" class="sidebar-link">Pipeline</a></li><li class="sidebar-sub-header"><a href="/practice/deepL.html#transformer模型使用-文本生成任务" class="sidebar-link">transformer模型使用——文本生成任务</a></li></ul></li><li class="sidebar-sub-header"><a href="/practice/deepL.html#深度学习本地实战" class="sidebar-link">深度学习本地实战</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/practice/deepL.html#本地部署一键抠图" class="sidebar-link">本地部署一键抠图</a></li></ul></li></ul></li><li><a href="/practice/canvas.html" class="sidebar-link">canvas 绘制</a></li><li><a href="/practice/react.html" class="sidebar-link">React + AntD 实战后台管理</a></li><li><a href="/practice/phaser.html" class="sidebar-link">使用phaser开发战旗游戏</a></li><li><a href="/practice/medicine.html" class="sidebar-link">小儿用药</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="深度学习与实践"><a href="#深度学习与实践" class="header-anchor">#</a> 深度学习与实践</h1> <h2 id="numpy常用api"><a href="#numpy常用api" class="header-anchor">#</a> numpy常用API</h2> <h2 id="torch常用api"><a href="#torch常用api" class="header-anchor">#</a> torch常用API</h2> <p>torch CPU版本安装使用<code>pip install torch</code>即可.</p> <h2 id="hugging-face实战"><a href="#hugging-face实战" class="header-anchor">#</a> Hugging Face实战</h2> <h3 id="transformer各种任务介绍"><a href="#transformer各种任务介绍" class="header-anchor">#</a> transformer各种任务介绍</h3> <h3 id="常用api"><a href="#常用api" class="header-anchor">#</a> 常用API</h3> <h3 id="pipeline"><a href="#pipeline" class="header-anchor">#</a> Pipeline</h3> <p>Pipeline可以很方便的使用huggingface提供的NLP任务, 示例代码如下:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 导入模块</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
<span class="token comment"># 指定pipeline的任务, 指定后, pipeline会自动从huggingface上下载相应的模型并加载, 并返回一个指定任务的Pipeline对象</span>
summarizer <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;summarization&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>其中, pipeline的第一个参数为<code>task: str = None</code>, 可选的值有很多, 可参考<a href="https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline.task" target="_blank" rel="noopener noreferrer">文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, 其中常用值有:</p> <ul><li>&quot;summarization&quot;: 文本摘要</li> <li>&quot;text2text-generation&quot;: 文本到文本生成</li> <li>&quot;text-classification&quot;或者&quot;sentiment-analysis&quot;: 文本分类</li> <li>&quot;text-generation&quot;: 文本生成</li> <li>&quot;token-classification&quot;或者&quot;ner&quot;: 命名实体识别</li> <li>&quot;translation&quot;: 翻译</li></ul> <p>pipeline的第二个参数为<code>model: str|PreTrainedModel | TFPreTrainedModel</code>, 该参数为可选值, 可传入指定模型, 如果是str类型, 则会加载本地或者自动从huggingface网站上下载对应名称的模型并加载, 因此本地代码可以写成:</p> <p><code>summarizer=pipeline('summarization','mypath/distilbart-cnn-12-6')</code></p> <p>由于model入参也可以直接以PreTrainedModel对象的形式传入，tokenizer也可以直接以PreTrainedTokenizer对象的形式传入。这种传入形式的写法示例：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;mypath/distilbart-cnn-12-6&quot;</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;mypath/distilbart-cnn-12-6&quot;</span><span class="token punctuation">)</span>

summarizer<span class="token operator">=</span>pipeline<span class="token punctuation">(</span><span class="token string">'summarization'</span><span class="token punctuation">,</span>model<span class="token operator">=</span>model<span class="token punctuation">,</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>

</code></pre></div><p>比较麻烦的是AutoClass类的选择, 在本文摘要里面使用的Auto类为<code>AutoModelForSeq2SeqLM</code>, 可以在huggingface上点击右上角的【&lt;/&gt;Use in Transformers】按钮，如下图所示。</p> <p><img src="https://pic.imgdb.cn/item/63f246b9f144a01007611cea.jpg" alt="查看transformers代码"></p> <p>代码返回的是一个<code>SummarizationPipeline</code>对象, 使用的话也很简单<code>summarizer(str_list: 需要摘要的文本列表, min_length=5, max_length=20)</code>即可.</p> <h3 id="transformer模型使用-文本生成任务"><a href="#transformer模型使用-文本生成任务" class="header-anchor">#</a> transformer模型使用——文本生成任务</h3> <h4 id="使用现有的模型生成文本"><a href="#使用现有的模型生成文本" class="header-anchor">#</a> 使用现有的模型生成文本</h4> <p>在<a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">抱抱脸（huggingface）<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>上开源的small或者tiny版本的中文NLG(nature language generate, 自然语言生成)模型主要有下列几个。</p> <ul><li><a href="https://huggingface.co/bigscience/bloom-560m" target="_blank" rel="noopener noreferrer">bigscience/bloom-560m<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，2022年5月26日由BigScience公司推出，模型大小1.12GB，支持48种语言。</li> <li><a href="https://huggingface.co/IDEA-CCNL/Wenzhong-GPT2-110M" target="_blank" rel="noopener noreferrer">IDEA-CCNL/Wenzhong-GPT2-110M<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, &quot;闻仲&quot;1.0版本, 属于IDEA 研究院&quot;封神榜&quot;开源模型系列, 2022年5月上传至huggingface, 模型大小274MB。</li> <li><a href="https://huggingface.co/IDEA-CCNL/Wenzhong2.0-GPT2-110M-BertTokenizer-chinese" target="_blank" rel="noopener noreferrer">IDEA-CCNL/Wenzhong2.0-GPT2-110M-BertTokenizer-chinese<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, &quot;闻仲&quot;2.0版本, 属于IDEA 研究院&quot;封神榜&quot;开源模型系列2.0版本, 基于BertTokenizer，实现字级别token，2022年12月上传至huggingface, 模型大小为421MB。</li> <li><a href="https://huggingface.co/uer/gpt2-distil-chinese-cluecorpussmall" target="_blank" rel="noopener noreferrer">uer/gpt2-chinese-cluecorpussmall<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，通用GPT2中文小模型, 2021年上传至huggingface, 模型大小为421MB。</li> <li><a href="https://huggingface.co/uer/gpt2-distil-chinese-cluecorpussmall" target="_blank" rel="noopener noreferrer">uer/gpt2-distil-chinese-cluecorpussmall<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，蒸馏后的GPT2中文小模型，2021年上传至huggingface，模型大小为244MB。</li></ul> <p>运行上述模型主要采用huggingface上的transformer模块进行，<a href="https://huggingface.co/docs/transformers/main/zh/index" target="_blank" rel="noopener noreferrer">官方中文文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>很详细。</p> <p>使用<code>pip install torch transformers numpy</code>安装必要模块</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizer<span class="token punctuation">,</span>GPT2LMHeadModel
<span class="token keyword">import</span> warnings

<span class="token comment"># 不显示警告信息</span>
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">&quot;ignore&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># 模型名称, 这里采用开源的闻仲GPT2 110M参数版本, 文件大小为421MB</span>
model_path <span class="token operator">=</span> <span class="token string">'IDEA-CCNL/Wenzhong2.0-GPT2-110M-BertTokenizer-chinese'</span>

<span class="token comment"># 创建分词器, 本地不存在则会从远程下载,这个文件不大,一般包括vocab.txt, tokenizer_config.json, 默认存储位置在C:\Users\用户名\.cache\huggingface\hub下</span>
tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># 创建模型, 比较大, 有421MB</span>
model <span class="token operator">=</span> GPT2LMHeadModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># 获得文本填充的后续词</span>
<span class="token keyword">def</span> <span class="token function">generate_word_level</span><span class="token punctuation">(</span>input_text<span class="token punctuation">,</span>n_return<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>max_length<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>top_p<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>input_text<span class="token punctuation">,</span>return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">,</span>add_special_tokens<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
    gen <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
                            inputs<span class="token operator">=</span>inputs<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                            max_length<span class="token operator">=</span>max_length<span class="token punctuation">,</span>
                            do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                            top_p<span class="token operator">=</span>top_p<span class="token punctuation">,</span>
                            eos_token_id<span class="token operator">=</span><span class="token number">21133</span><span class="token punctuation">,</span>
                            pad_token_id<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
                            num_return_sequences<span class="token operator">=</span>n_return<span class="token punctuation">)</span>

    sentences <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>gen<span class="token punctuation">)</span>
    <span class="token keyword">for</span> idx<span class="token punctuation">,</span>sentence <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'sentence </span><span class="token interpolation"><span class="token punctuation">{</span>idx<span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{</span>sentence<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-----'</span><span class="token operator">*</span><span class="token number">30</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> gen

<span class="token comment"># 开始测试</span>
outputs <span class="token operator">=</span> generate_word_level<span class="token punctuation">(</span><span class="token string">'实践出真知，实践长才干。'</span><span class="token punctuation">,</span>n_return<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>max_length<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>
</code></pre></div><h4 id="huggingface模型转为onnx格式"><a href="#huggingface模型转为onnx格式" class="header-anchor">#</a> huggingface模型转为onnx格式</h4> <p>huggingface提供了三种方式进行转换, 不过我测试之后只在一个代码上运行成功了.</p> <div class="language-python extra-class"><pre class="language-python"><code>
<span class="token keyword">from</span> optimum<span class="token punctuation">.</span>onnxruntime <span class="token keyword">import</span> ORTModelForSequenceClassification

model_id <span class="token operator">=</span> <span class="token string">'IDEA-CCNL/Wenzhong2.0-GPT2-110M-BertTokenizer-chinese'</span>

<span class="token comment"># 相当于使用ORTModel的方式进行模型加载, 来源transformer, 其中参数设置为from_transformers=True</span>
<span class="token comment"># 运行代码成功之后, 用everything在全盘搜索&quot;*.onnx&quot;, 最新生成的就是转换后的onnx模型</span>
model <span class="token operator">=</span> ORTModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span> from_transformers<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="huggingface模型微调"><a href="#huggingface模型微调" class="header-anchor">#</a> huggingface模型微调</h4> <h2 id="深度学习本地实战"><a href="#深度学习本地实战" class="header-anchor">#</a> 深度学习本地实战</h2> <h3 id="本地部署一键抠图"><a href="#本地部署一键抠图" class="header-anchor">#</a> 本地部署一键抠图</h3> <p>一键抠图使用的是python库<a href="https://github.com/plemeri/transparent-background" target="_blank" rel="noopener noreferrer">Transparent Background<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，不支持3.7及以下版本，建议使用3.10版本的python</p> <p>1.安装v3.10.10的64位python<a href="https://www.python.org/ftp/python/3.10.10/python-3.10.10-amd64.exe" target="_blank" rel="noopener noreferrer">下载地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>2.安装必须的依赖库</p> <div class="language-py extra-class"><pre class="language-py"><code><span class="token comment"># CPU 版本：</span>
pip3 install torch torchvision torchaudio <span class="token operator">-</span>i https<span class="token punctuation">:</span><span class="token operator">//</span>mirrors<span class="token punctuation">.</span>aliyun<span class="token punctuation">.</span>com<span class="token operator">/</span>pypi<span class="token operator">/</span>simple
<span class="token comment"># GPU 版本：</span>
pip3 install torch torchvision torchaudio <span class="token operator">-</span><span class="token operator">-</span>index<span class="token operator">-</span>url https<span class="token punctuation">:</span><span class="token operator">//</span>download<span class="token punctuation">.</span>pytorch<span class="token punctuation">.</span>org<span class="token operator">/</span>whl<span class="token operator">/</span>cu118
</code></pre></div><p>3.安装 Transparent BG，使用命令<code>pip3 install transparent-background -i https://mirrors.aliyun.com/pypi/simple</code></p> <p>4.下载模型和一键发送的批处理文件，<a href="https://pan.baidu.com/s/10yZfxegIqgl9V3QvH4k0EA?pwd=n49d" target="_blank" rel="noopener noreferrer">百度网盘地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，下载后解压<code>TransparentBG_Win.7z</code>文件，然后双击<code>开始.bat</code>文件安装快捷方式。</p> <p>5.使用方法，支持png和jpg格式的图片，对着图片文件点击右键，选择“发送到-一键抠图”，如下图所示，抠图完成后会自动在原目录生成抠图后的图片。</p> <p><img src="https://pic.imgdb.cn/item/65f053b39f345e8d032a1fd6.png" alt="一键抠图"></p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新于:</span> <span class="time">3/12/2024, 9:16:49 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/practice/book.html" class="prev">
        外文技术书籍推荐
      </a></span> <span class="next"><a href="/practice/canvas.html">
        canvas 绘制
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/assets/js/app.172e5c27.js" defer></script><script src="/assets/js/2.983eb755.js" defer></script><script src="/assets/js/50.f25489e0.js" defer></script>
  </body>
</html>
